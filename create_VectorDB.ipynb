{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katie/Coding/NASA_RAG/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/katie/Coding/NASA_RAG/.venv/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "data_path = 'nasa_articles/'\n",
    "faiss_path = \"faiss_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3399.75it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_documents():\n",
    "    loader = DirectoryLoader(data_path, glob='*.md', show_progress=True, \n",
    "                             use_multithreading=True, loader_cls=TextLoader)\n",
    "    docs = loader.load()\n",
    "    return docs\n",
    "\n",
    "docs = load_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1000 documents into 12854 chunks\n",
      "“To put it simply, this is the kind of rock we had hoped to find when we decided to investigate Jezero Crater,” said Ken Farley, project scientist for Perseverance at Caltech in Pasadena, California. “Nearly all the minerals in the rock we just sampled were made in water; on Earth, water-deposited minerals are often good at trapping and preserving ancient organic material and biosignatures. The rock can even tell us about Mars climate conditions that were present when it was formed.”\n",
      "{'source': 'nasa_articles/nasa_article_355.md', 'start_index': 1094}\n"
     ]
    }
   ],
   "source": [
    "# Split the documents into chunks so we can retrieve information more granularly (rather than the entire document)\n",
    "\n",
    "def split_text(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size= 500,\n",
    "        chunk_overlap = 250,\n",
    "        length_function = len,\n",
    "        add_start_index = True,\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f'Split {len(documents)} documents into {len(chunks)} chunks')\n",
    "    \n",
    "    # Demonstrate what a chunk looks like (not necessary code)\n",
    "    document = chunks[10]\n",
    "    print(document.page_content)\n",
    "    print(document.metadata)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "chunks = split_text(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katie/Coding/NASA_RAG/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing previous contents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ingesting documents: 100%|██████████| 1000/1000 [06:08<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving DB\n",
      "Saved 12854 chunks to faiss_db.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DB to later query each chunk. (Uses vector embeddings as the key)\n",
    "# Create vector embeddings for each chunk\n",
    "# Embeddings are vectors in an n-dimensonal space. Eg. similar words or chunks will point in similar directions.\n",
    "# Embeddings from OpenAI for example (but costs per x tokens) -> Alternative Embedding from Huggingface: Opensource & free \n",
    " \n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "def save_to_faiss(chunks: list[Document]):\n",
    "    if os.path.exists(faiss_path):\n",
    "        # clear previous chroma dbs\n",
    "        print(\"Removing previous contents.\")\n",
    "        shutil.rmtree(faiss_path)\n",
    "\n",
    "    db = None\n",
    "    with tqdm(total=len(docs), desc=\"Ingesting documents\") as pbar:\n",
    "        for d in docs:\n",
    "            if db:\n",
    "                db.add_documents([d])\n",
    "            else:\n",
    "                db = FAISS.from_documents([d], embeddings)\n",
    "            pbar.update(1) \n",
    "\n",
    "    try:\n",
    "        # print(\"Creating VectorStore.\")\n",
    "        # db = FAISS.from_documents(docs, embeddings)\n",
    "        print(\"Saving DB\")\n",
    "        db.save_local(folder_path=\"faiss_db\", index_name=\"nasa_index\")\n",
    "        print(f'Saved {len(chunks)} chunks to {faiss_path}.')\n",
    "    except (ValueError, RuntimeError) as e:\n",
    "        print(\"Fiass store failed \\n\", e)\n",
    "\n",
    "save_to_faiss(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katie/Coding/NASA_RAG/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3651]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"This is an example sentence\", \"Each sentence has been converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embedding_1= model.encode(sentences[0], convert_to_tensor=True)\n",
    "embedding_2 = model.encode(sentences[1], convert_to_tensor=True)\n",
    "\n",
    "util.pytorch_cos_sim(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
