The Next Accident: How Do We Prevent It? 
 By Andrew Chaikin, Independent Space Historian and member of the NESC Human Factors Technical Discipline Team

I recently watched NESC Deputy Director Mike Kirsch stand before a roomful of engineers at the Langley Research Center and tell them that with every passing day, NASA breaks a record: the longest stretch without a major accident in the nation’s human spaceflight program since the Space Shuttle Columbia disintegrated during reentry on February 1, 2003. NASA’s challenge, he told them, was to make sure the record keeps being broken.

Mike’s sobering message set the perfect tone for my presentation of “Principles of Success in Spaceflight,” the class I created with Victoria Kohl on the human behavior elements of success and failure in spaceflight projects. With the NESC’s support, I have given it at every NASA center, and it’s always a rewarding experience. You can’t spend the day with a group of NASA engineers and not experience their keen intelligence, passion, and commitment to excellence. As I lead them through case studies of the Apollo 1 fire in 1967, the Challenger accident in 1986, and Columbia, I tell them that no matter how good we are at the “rocket science,” we invite failure if we don’t pay attention to the attitudes, beliefs, and assumptions we bring to the work—in short, our mindset.

Before the Apollo fire, there was a widespread belief that because Mercury and Gemini had used pure oxygen with no fires, there wouldn’t be any in Apollo. And the Apollo spacecraft program manager missed opportunities to prevent the accident due to his belief that the fire hazard created by combining pure oxygen with exposed wiring and flammable materials was not a “real” problem, one that warranted slowing the train barreling down the tracks to meet John F. Kennedy’s end-of-the-decade deadline for a lunar landing.

When I talk about the Challenger accident, I caution that it’s essential to pay attention to the stories we tell ourselves. NASA had promised itself and Congress that the Shuttle would make spaceflight routine and affordable, a goal that required unrealistically high flight rates. Mounting schedule pressure in the lead-up to Challenger skewed decision makers’ perceptions of the SRB field joint anomalies that had occurred intermittently on previous launches and were not well understood. In the Columbia discussion, I recount the shocking swiftness with which NASA lost the lessons of Challenger and paved the way for another accident with renewed schedule pressure and a belief that external tank foam shedding was “not a safety of flight issue.” Accidents jolt us into new awareness, but Columbia is a painful reminder that awareness has a shelf life.

What will it take to keep breaking the record that Mike spoke about? I believe we must talk to each other regularly about the behaviors that either invite success or lead us down the slippery slope to failure. Are we in the grip of what I call the “reality distortion field,” created by cost, schedule, and/or political pressure, that clouds our perceptions of risk? Are we unconsciously indulging in hard-wired “us vs. them” tribal behaviors that cut us off from the diverse “spotlights of awareness” we must have to navigate the unforgiving demands of human spaceflight? Are we telling ourselves a story that, under clear-eyed scrutiny, doesn’t hold up? These are the questions we need to ask ourselves again and again. The answers are critical.