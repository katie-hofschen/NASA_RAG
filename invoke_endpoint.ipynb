{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "\n",
    "boto_session = boto3.Session(profile_name='dev-profile')\n",
    "client = boto_session.client(\"sagemaker-runtime\")\n",
    "\n",
    "# This has to be the same name as used in terraform to name the endpoint\n",
    "ENDPOINT_NAME = \"mistral-model-endpoint\"\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "#os.environ[\"HF_API_TOKEN\"] = 'token'\n",
    "# HF_API_TOKEN= os.environ[\"HF_API_TOKEN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check: Is the endpoint functioning as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"<s>[INST] Write a poem about a cat named Homer. [/INST] In a quiet little nook, beneath the moon's soft glow,\\nLived a cat named Homer, known to the town,\\nHis fur was thick and warm, a coat of rich brown,\\nHis eyes shimmered in the dark, like polished gold.\\n\\nHomer was no ordinary feline, that much was true,\\nHe held a secret wisdom, in those ancient eyes,\\nA gentle soul, with a meow and a mou,\\nHe\"}]\n"
     ]
    }
   ],
   "source": [
    "# first test to verify endpoint is functioning correctly\n",
    "user_message = \"Write a poem about a cat named Homer.\"\n",
    "prompt = f\"<s>[INST] {user_message} [/INST]\"\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": prompt,\n",
    "}\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=\"application/json\",\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG using the hosted endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katie/Coding/NASA_RAG/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# loading the vector DB with all of our chunked nasa articles\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "db = FAISS.load_local(folder_path=\"faiss_db/\", embeddings=embeddings, index_name=\"nasa_index\", allow_dangerous_deserialization=True)\n",
    "\n",
    "# This retriever returns the top 5 similar chunks\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Define the SageMaker configuration model\n",
    "class SageMakerConfig(BaseModel):\n",
    "    endpoint_name: str = Field(...)\n",
    "    profile_name: str = Field('default')\n",
    "\n",
    "# Define the custom SageMaker LLM class\n",
    "class SageMakerLLM(LLM):\n",
    "    endpoint_name: str\n",
    "    profile_name: str\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def _call(self, prompt, **kwargs):\n",
    "        payload = {\"inputs\": prompt}\n",
    "        response = boto3.Session(profile_name=self.profile_name).client(\"sagemaker-runtime\").invoke_endpoint(\n",
    "            EndpointName=self.endpoint_name,\n",
    "            ContentType=\"application/json\",\n",
    "            Accept=\"application/json\",\n",
    "            Body=json.dumps(payload)\n",
    "        )\n",
    "        result = json.loads(response['Body'].read().decode())\n",
    "        \n",
    "        # Print out the response for debugging\n",
    "        # print(\"Raw response from SageMaker endpoint:\", result)\n",
    "        \n",
    "        # Assuming the response is a list of dictionaries with 'generated_text' keys\n",
    "        if isinstance(result, list) and 'generated_text' in result[0]:\n",
    "            return result[0]['generated_text']\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected response format from SageMaker endpoint\")\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"sagemaker_llm\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the custom SageMaker LLM\n",
    "config = SageMakerConfig(endpoint_name=\"mistral-model-endpoint\", profile_name='dev-profile')\n",
    "sagemaker_llm = SageMakerLLM(endpoint_name=config.endpoint_name, profile_name=config.profile_name)\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = \"\"\"\n",
    "Answer the question based on your knowledge. Use the following context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "</s>\n",
    "\n",
    "{question}\n",
    "</s>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain setup\n",
    "llm_chain = prompt | sagemaker_llm | StrOutputParser()\n",
    "\n",
    "# Combine retriever and LLM chain\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | llm_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on your knowledge. Use the following context to help:\n",
      "\n",
      "[Document(page_content='Sols 4120-4122: Mars Throws Us a Curveball! \\n As we previously documented, the first “Mineral King” drill hole did not quite reach the target depth that we typically desire to ensure that we have enough sample in the drill stem to deliver to our internal CheMin and SAM instruments. While we did get a successful X-ray diffraction CheMin analysis, we did not quite have enough sample left for SAM to be able to complete their Evolved Gas Analysis (EGA). The rover engineers selected a new potential drill spot on the same block, and this morning we got the results of the APXS, MAHLI and preload test (to check for stability and drillability) on that spot. While the chemistry and imaging indicated that it was a good candidate the preload test did not pass. The selected target was just a little too close to the rover. As the APXS strategic planner today, I reported the results of the APXS chemical analysis to the team; we were looking for the “Mineral King2” area to have a similar composition to the first drill target. We found out about the failure of the preload test as we were ready to deliver our preliminary plan, but we are all used to reacting to the surprises that Mars occasionally sends our way! The science, engineering and uplink teams did an excellent job responding to the sudden change of plans and we managed to come up with a homerun, version 2 of our plan to accommodate the late-breaking news, taking advantage of the extra power and time available to us, given that we were not proceeding with drilling!', metadata={'source': 'nasa_articles/nasa_article_557.md'}), Document(page_content='Sols 4186-4188: Almost there… \\n The rover planning engineers yet again did a great job navigating through the large bedrock blocks that litter the terrain in front of us. We are getting ever closer to being able to cross the Gediz Vallis channel and associated deposits, a feature we identified long before landing and of high scientific interest. As a member of the group responsible for planning the observations we hope to get on the Gediz Vallis deposits and associated landforms (called the Channel Surfers), I am very excited to finally be at this point in the mission. To help decide where to drive onto the deposit, we are driving a little closer to the edge and taking extra post-drive imaging to aid in that decision. We are also acquiring a large Mastcam mosaic of an area of the deposit we hope to study in more detail, “Arc Pass.”', metadata={'source': 'nasa_articles/nasa_article_18.md'}), Document(page_content=\"Sols 4116-4117: Rover Kinesthetics \\n It has been a busy and exciting week for Curiosity and its science team. Our intrepid rover successfully drilled its 40th sample on Mars and today followed it up with an intensive campaign to characterize the tailings expelled while drilling “Mineral King.” When APXS analyzes a target, it receives signals from the top millimeter or less of the sample (similar to ChemCam, depending on the number of laser pulses conducted). Drilled material extracted by Curiosity and fed to SAM and/or CheMin, however, is typically extracted from 2+ cm below the surface. Drill tailings therefore provide APXS (and ChemCam) a more representative sample of the material analyzed by CheMin and/or SAM than pre-drill analyses of the target surface. Given images acquired previously showed a visually heterogeneous tailings pile, the 4116-4117 plan focused in part on acquiring MAHLI images and APXS analyses of not one but two spots on Mineral King's tailings.\", metadata={'source': 'nasa_articles/nasa_article_613.md'})]\n",
      "\n",
      "</s>\n",
      "\n",
      "What are the latest findings from the Mars Rover?\n",
      "</s>\n",
      "\n",
      "The Mars Rover team has been making progress in drilling and analyzing samples. In the latest findings, they had initial success with the \"Mineral King\" drill hole, getting a successful X-ray diffraction CheMin analysis but not quite enough sample for SAM's Evolved Gas Analysis (EGA). They then selected a new potential drill spot on the same block for further analysis, but the preload test did not pass due to the spot being too\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "question = \"What are the latest findings from the Mars Rover?\"\n",
    "\n",
    "# Invoke the RAG chain\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
